{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# My modules\n",
    "from utils import *\n",
    "\n",
    "# Notebook Settings\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('data/n_forecast_preprocessed.parquet', engine='pyarrow', dtype_backend='numpy_nullable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('sales_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "# convert to float the n_transactions column\n",
    "data['n_transactions'] = data['n_transactions'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['store_hashed'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting for all stores\n",
    "\n",
    "1. First of all we need to make all stores data stationary to be able to use ARIMA model. We will use differencing to make data stationary.\n",
    "2. Then we will use auto_arima function to find the best parameters for ARIMA model.\n",
    "3. Finally we will use ARIMA model to forecast number of transactions for each store.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check stationarity for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_stores, non_stationary_stores = test_stores_stationarity(data, plot=False, results=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary_stores will have d=0 for arima model\n",
    "# stationary_stores_1 will have d=1 for arima model\n",
    "# stationary_store_2 will have d=2 for arima model\n",
    "stationary_stores_1, non_stationary_stores_1 = differencing(data, non_stationary_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all stores stationarity after differencing\n",
    "data = data.dropna()\n",
    "\n",
    "stationary_stores_2, non_stationary_stores_2 = test_stores_stationarity(data, plot=False, results=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning for each store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load again the dataset\n",
    "data = pd.read_parquet('data/n_forecast_preprocessed.parquet', engine='pyarrow', dtype_backend='numpy_nullable')\n",
    "data.set_index('sales_date', inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "# convert to float the n_transactions column\n",
    "data['n_transactions'] = data['n_transactions'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stationary_stores   (d=0)\n",
    "# stationary_stores_1 (d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe with pdq values\n",
    "store_params = pd.DataFrame(columns=['store', 'pdq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the best hyperparameters for ARIMA model\n",
    "for store in stationary_stores:\n",
    "    print(f\"Store: {store}\")\n",
    "                      \n",
    "    data_store = data[data['store_hashed'] == store]\n",
    "    \n",
    "    best_params = arima_hyperparameters(data_store['n_transactions'], diff=0)\n",
    "    print(best_params)\n",
    "    store_params = pd.concat([store_params, pd.DataFrame({'store': [store], 'pdq': [best_params]})], ignore_index=True)\n",
    "    \n",
    "    # save the dataframe as csv file\n",
    "    # store_params.to_csv('data/stores_arima_params.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store in stationary_stores_1:\n",
    "    print(f\"Store: {store}\")\n",
    "\n",
    "    data_store = data[data['store_hashed'] == store]\n",
    "\n",
    "    best_params = arima_hyperparameters(data_store['n_transactions'], diff=1)\n",
    "    print(best_params)\n",
    "    store_params = pd.concat([store_params, pd.DataFrame({'store': [store], 'pdq': [best_params]})], ignore_index=True)\n",
    "\n",
    "    # save the dataframe as csv file\n",
    "\n",
    "store_params.to_csv('data/stores_arima_params.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
